{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "eip3phase2sess2_2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZ64Sn5-THJw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlfzKk1mU7Dd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMtnDgGMU9B0",
        "colab_type": "code",
        "outputId": "9ef3b68f-1641-43d1-876e-69257600164c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "drive.mount('/content/drive')\n",
        "!ls /content/drive/My\\ Drive/EIP3Phase2"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "model\tsaved_models\t Session1_1.ipynb  wonderland.txt\n",
            "model2\tsession1_1.hdf5  Session1_2.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE8eCy2ITNCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "# load ascii text and covert to lowercase\n",
        "filename = \"/content/drive/My Drive/EIP3Phase2/wonderland.txt\"\n",
        "raw_text = open(filename).read()\n",
        "raw_text = raw_text.lower()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUMTw6HSDcoM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "4af544e3-8f0d-489d-8899-fcd56ce7e8ab"
      },
      "source": [
        "# create mapping of unique chars to integers, and a reverse mapping\n",
        "chars = sorted(list(set(raw_text)))\n",
        "print(\"len = \", len(chars), chars)\n",
        "puncts = [',', '!', '#', '$', '%', '*', ':', '@', ';', '?', '-', '/', '_', ]\n",
        "print(\"len = \", len(puncts), puncts)\n",
        "\n",
        "sourceset = list(raw_text)\n",
        "for x in puncts:\n",
        "   [sourceset.remove(x) for Item in range(sourceset.count(x))]\n",
        "\n",
        "#chars = [x for x in puncts]\n",
        "[chars.remove(item) for item in puncts]\n",
        "print(\"len = \", len(chars), chars)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "len =  59 ['\\n', ' ', '!', '\"', '#', '$', '%', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '@', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\ufeff']\n",
            "len =  13 [',', '!', '#', '$', '%', '*', ':', '@', ';', '?', '-', '/', '_']\n",
            "len =  46 ['\\n', ' ', '\"', \"'\", '(', ')', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\ufeff']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71ZFWl0pGhE4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "445dc96d-87a0-4b81-f373-4d5edfb2405c"
      },
      "source": [
        "\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
        "# summarize the loaded data\n",
        "n_chars = len(raw_text)\n",
        "n_srcchars = len(sourceset)\n",
        "n_vocab = len(chars)\n",
        "print(\"Total Characters: \", n_chars)\n",
        "print(\"Total Source Characters: \", n_srcchars)\n",
        "print(\"Total Vocab: \", n_vocab)\n",
        "\n",
        "raw_text = sourceset\n",
        "n_chars = n_srcchars"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters:  163781\n",
            "Total Source Characters:  159247\n",
            "Total Vocab:  46\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0JVynJWWjr5",
        "colab_type": "code",
        "outputId": "17ecd0fb-7a4a-4c26-965f-18619ace38ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "\tseq_in = raw_text[i:i + seq_length]\n",
        "\tseq_out = raw_text[i + seq_length]\n",
        "\tdataX.append([char_to_int[char] for char in seq_in])\n",
        "\tdataY.append(char_to_int[seq_out])\n",
        "  \n",
        "n_patterns = len(dataX)\n",
        "print(\"Total Patterns: \", n_patterns)\n",
        "\n",
        "# padding doesn't make sense for this as seq_length is fixed here\n",
        "# However for completeness of assignment using this here with 1 extra chars\n",
        "savedDataX = dataX\n",
        "dataX = pad_sequences(dataX, maxlen=101)\n",
        "n_patterns = len(dataX)\n",
        "\n",
        "print(\"Total Patterns: \", n_patterns)\n",
        "\n",
        "# reshape X to be [samples, time steps, features]\n",
        "X = numpy.reshape(dataX, (n_patterns, 101, 1))\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "# one hot encode the output variable\n",
        "y = np_utils.to_categorical(dataY)\n",
        "# define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(256))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Patterns:  159147\n",
            "Total Patterns:  159147\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xuwbvqfXaMG",
        "colab_type": "code",
        "outputId": "58addcd9-5822-48b8-ee95-230adb5f0ca7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "filepath=\"/content/drive/My Drive/EIP3Phase2/model2/weights-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]\n",
        "# fit the model\n",
        "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "159147/159147 [==============================] - 336s 2ms/step - loss: 2.9071\n",
            "\n",
            "Epoch 00001: loss improved from inf to 2.90714, saving model to /content/drive/My Drive/EIP3Phase2/model2/weights-01-2.9071.hdf5\n",
            "Epoch 2/20\n",
            "159147/159147 [==============================] - 331s 2ms/step - loss: 2.7943\n",
            "\n",
            "Epoch 00002: loss improved from 2.90714 to 2.79428, saving model to /content/drive/My Drive/EIP3Phase2/model2/weights-02-2.7943.hdf5\n",
            "Epoch 3/20\n",
            "159147/159147 [==============================] - 332s 2ms/step - loss: 2.6952\n",
            "\n",
            "Epoch 00003: loss improved from 2.79428 to 2.69523, saving model to /content/drive/My Drive/EIP3Phase2/model2/weights-03-2.6952.hdf5\n",
            "Epoch 4/20\n",
            "159147/159147 [==============================] - 332s 2ms/step - loss: 2.6025\n",
            "\n",
            "Epoch 00004: loss improved from 2.69523 to 2.60251, saving model to /content/drive/My Drive/EIP3Phase2/model2/weights-04-2.6025.hdf5\n",
            "Epoch 5/20\n",
            "159147/159147 [==============================] - 334s 2ms/step - loss: 2.5316\n",
            "\n",
            "Epoch 00005: loss improved from 2.60251 to 2.53161, saving model to /content/drive/My Drive/EIP3Phase2/model2/weights-05-2.5316.hdf5\n",
            "Epoch 6/20\n",
            "159147/159147 [==============================] - 334s 2ms/step - loss: 2.4729\n",
            "\n",
            "Epoch 00006: loss improved from 2.53161 to 2.47291, saving model to /content/drive/My Drive/EIP3Phase2/model2/weights-06-2.4729.hdf5\n",
            "Epoch 7/20\n",
            "159147/159147 [==============================] - 329s 2ms/step - loss: 2.4174\n",
            "\n",
            "Epoch 00007: loss improved from 2.47291 to 2.41742, saving model to /content/drive/My Drive/EIP3Phase2/model2/weights-07-2.4174.hdf5\n",
            "Epoch 8/20\n",
            "159147/159147 [==============================] - 331s 2ms/step - loss: 2.3603\n",
            "\n",
            "Epoch 00008: loss improved from 2.41742 to 2.36030, saving model to /content/drive/My Drive/EIP3Phase2/model2/weights-08-2.3603.hdf5\n",
            "Epoch 9/20\n",
            "159147/159147 [==============================] - 332s 2ms/step - loss: 2.3138\n",
            "\n",
            "Epoch 00009: loss improved from 2.36030 to 2.31381, saving model to /content/drive/My Drive/EIP3Phase2/model2/weights-09-2.3138.hdf5\n",
            "Epoch 10/20\n",
            "159147/159147 [==============================] - 333s 2ms/step - loss: 2.2690\n",
            "\n",
            "Epoch 00010: loss improved from 2.31381 to 2.26902, saving model to /content/drive/My Drive/EIP3Phase2/model2/weights-10-2.2690.hdf5\n",
            "Epoch 11/20\n",
            "159147/159147 [==============================] - 330s 2ms/step - loss: 2.2274\n",
            "\n",
            "Epoch 00011: loss improved from 2.26902 to 2.22737, saving model to /content/drive/My Drive/EIP3Phase2/model2/weights-11-2.2274.hdf5\n",
            "Epoch 12/20\n",
            "159147/159147 [==============================] - 330s 2ms/step - loss: 2.1878\n",
            "\n",
            "Epoch 00012: loss improved from 2.22737 to 2.18779, saving model to /content/drive/My Drive/EIP3Phase2/model2/weights-12-2.1878.hdf5\n",
            "Epoch 13/20\n",
            "159147/159147 [==============================] - 327s 2ms/step - loss: 2.1545\n",
            "\n",
            "Epoch 00013: loss improved from 2.18779 to 2.15449, saving model to /content/drive/My Drive/EIP3Phase2/model2/weights-13-2.1545.hdf5\n",
            "Epoch 14/20\n",
            "159147/159147 [==============================] - 332s 2ms/step - loss: 2.1311\n",
            "\n",
            "Epoch 00014: loss improved from 2.15449 to 2.13112, saving model to /content/drive/My Drive/EIP3Phase2/model2/weights-14-2.1311.hdf5\n",
            "Epoch 15/20\n",
            "159147/159147 [==============================] - 330s 2ms/step - loss: 2.1037\n",
            "\n",
            "Epoch 00015: loss improved from 2.13112 to 2.10373, saving model to /content/drive/My Drive/EIP3Phase2/model2/weights-15-2.1037.hdf5\n",
            "Epoch 16/20\n",
            "159147/159147 [==============================] - 334s 2ms/step - loss: 2.0777\n",
            "\n",
            "Epoch 00016: loss improved from 2.10373 to 2.07774, saving model to /content/drive/My Drive/EIP3Phase2/model2/weights-16-2.0777.hdf5\n",
            "Epoch 17/20\n",
            "159147/159147 [==============================] - 331s 2ms/step - loss: 2.0607\n",
            "\n",
            "Epoch 00017: loss improved from 2.07774 to 2.06075, saving model to /content/drive/My Drive/EIP3Phase2/model2/weights-17-2.0607.hdf5\n",
            "Epoch 18/20\n",
            "159147/159147 [==============================] - 333s 2ms/step - loss: 2.0424\n",
            "\n",
            "Epoch 00018: loss improved from 2.06075 to 2.04239, saving model to /content/drive/My Drive/EIP3Phase2/model2/weights-18-2.0424.hdf5\n",
            "Epoch 19/20\n",
            "159147/159147 [==============================] - 333s 2ms/step - loss: 2.0234\n",
            "\n",
            "Epoch 00019: loss improved from 2.04239 to 2.02336, saving model to /content/drive/My Drive/EIP3Phase2/model2/weights-19-2.0234.hdf5\n",
            "Epoch 20/20\n",
            "159147/159147 [==============================] - 337s 2ms/step - loss: 2.0081\n",
            "\n",
            "Epoch 00020: loss improved from 2.02336 to 2.00813, saving model to /content/drive/My Drive/EIP3Phase2/model2/weights-20-2.0081.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f88108e5b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EHnRmufV5ko",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "bc15a0a9-b72c-49e1-9360-567107e6c3b7"
      },
      "source": [
        "# load the network weights\n",
        "from keras.models import load_model\n",
        "\n",
        "filepath2=\"/content/drive/My Drive/EIP3Phase2/model2/weights-20-2.0081.hdf5\"\n",
        "model = load_model('/content/drive/My Drive/EIP3Phase2/model2/weights-20-2.0081.hdf5')\n",
        "#model.load_weights(filepath2)\n",
        "#model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "# pick a random seed\n",
        "print(len(dataX))\n",
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print(\"Seed: Len\", len(pattern))\n",
        "#print(pattern)\n",
        "\n",
        "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
        "# generate characters\n"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "159147\n",
            "Seed: Len 101\n",
            "\" \n",
            "n waiting by the little door so she went\n",
            "back to the table half hoping she might find another key on \"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-MzvvcYou9V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "a48cbc64-ea0f-4252-dfea-90b353b6abc9"
      },
      "source": [
        "\n",
        "for i in range(500):\n",
        "  x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "  x = x / float(n_vocab)\n",
        "  prediction = model.predict(x, verbose=0)\n",
        "  index = numpy.argmax(prediction)\n",
        "  #print(index)\n",
        "  result = int_to_char[index]\n",
        "  seq_in = [int_to_char[value] for value in pattern]\n",
        "  sys.stdout.write(result)\n",
        "  pattern = numpy.append(pattern, index)\n",
        "  pattern = pattern[1:len(pattern)]\n",
        "  \n",
        "print(\"\\nDone.\")"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nh tonet oolhr onad ienns a didielelelelenen a didnnsyenes toketeyk toketeyk toketeyeleie ioat tonet oel brl tokete ioennser ons tonet oadl ons toketenen soketenedne nonh toketenennsy toketenedne nonhi ioenes toketenedne nonhi ioenes toketenedne nonh toketenennsenei b dicens to an enl nosety a dicens a. \n",
            "a.1\n",
            "\n",
            "11.  ioicnsenel ot a0  a0  ioaies a de71  ioent to tiatl tonet oolh toketeyeleie i tonet onad ioannsyenes toketeyk toketeyk toketeyk toketeyk toketeyeleie ioat tonet oel brl toketenedne ton\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dp757BSIx-z1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "a78df51f-a3b3-4118-f696-9bb46f288102"
      },
      "source": [
        "# An earlier model without the padded sequences has better pridictions\n",
        "# load the network weights\n",
        "\n",
        "filename = \"/content/drive/My Drive/EIP3Phase2/wonderland.txt\"\n",
        "raw_text = open(filename).read()\n",
        "raw_text = raw_text.lower()\n",
        "# create mapping of unique chars to integers, and a reverse mapping\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
        "# summarize the loaded data\n",
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print(\"Total Characters: \", n_chars)\n",
        "print(\"Total Vocab: \", n_vocab)\n",
        "\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "\tseq_in = raw_text[i:i + seq_length]\n",
        "\tseq_out = raw_text[i + seq_length]\n",
        "\tdataX.append([char_to_int[char] for char in seq_in])\n",
        "\tdataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "print(\"Total Patterns: \", n_patterns)\n",
        "\n",
        "model = load_model('/content/drive/My Drive/EIP3Phase2/model/weights-20-1.6101.hdf5')\n",
        "#model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "# pick a random seed\n",
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print(\"Seed:\")\n",
        "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
        "# generate characters\n",
        "for i in range(500):\n",
        "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "\tx = x / float(n_vocab)\n",
        "\tprediction = model.predict(x, verbose=0)\n",
        "\tindex = numpy.argmax(prediction)\n",
        "\tresult = int_to_char[index]\n",
        "\tseq_in = [int_to_char[value] for value in pattern]\n",
        "\tsys.stdout.write(result)\n",
        "\tpattern.append(index)\n",
        "\tpattern = pattern[1:len(pattern)]\n",
        "print(\"\\nDone.\")"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters:  163781\n",
            "Total Vocab:  59\n",
            "Total Patterns:  163681\n",
            "Seed:\n",
            "\" took me for his housemaid,' she said to herself as she ran. 'how\n",
            "surprised he'll be when he finds ou \"\n",
            "t of the wouds beain, and the doom thing that she was not a little boorer of the sabbit sas the danled of the sabbit sas the danled oo the thoee of the garden with the tooke. \n",
            "'it was a mine things,' said the ming, 'it would be a little gord the door tiat she was a little bool the little boos in the thme, and the was talking about the little gord of the tooe of the words as she could her hn the tooke. \n",
            "'it was a reree of the soiee,                                                                 \n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}